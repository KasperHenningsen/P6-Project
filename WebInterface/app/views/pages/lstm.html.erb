<div class="container">

  <img src="https://en.wikipedia.org/wiki/Recurrent_neural_network#/media/File:Long_Short-Term_Memory.svg">

  <h3>LSTM - Long short-term memory</h3>

  <p>
    A long short-term memory (LSTM) network is a type of neural network that is commonly used for processing sequential
    data, such as speech and natural language. LSTMs are a variation of the recurrent neural
    network <%= link_to 'RNN', '/rnn' %> architecture,
    which allows them to handle long-term dependencies more effectively. LSTMs use a memory cell that can store
    information over time and three gates (input, forget, and output) that regulate the flow of information into and out
    of the cell. This enables LSTMs to selectively retain and discard information, making them well-suited for tasks
    that require the model to remember important features of the data while filtering out irrelevant information. LSTMs
    are particularly useful in applications such as language modeling, machine translation, and speech recognition.
    Overall, the effectiveness of the LSTM architecture has made it a popular choice for many sequence modeling tasks.
  </p>
</div>