<div class="container">

  <img src="https://en.wikipedia.org/wiki/Recurrent_neural_network#/media/File:Recurrent_neural_network_unfold.svg">

  <h3>Gru - Gated recurrent unit</h3>

  <p>
    A gated recurrent unit (GRU) is a type of neural network that is commonly used for natural language processing tasks
    such as language translation and speech recognition.
    GRUs are a variation of the more commonly known nural network <%= link_to 'RNN', '/rnn' %>
    architecture, which allows them to
    handle sequential data with greater efficiency.
    Unlike standard <%= link_to 'RNNs', '/rnn' %>, GRUs have gating mechanisms that selectively allow information to
    pass through the network,
    making them less susceptible to the vanishing gradient problem that can occur in longer sequences.
    This allows GRUs to learn long-term dependencies more effectively and make more accurate predictions.
    Overall, the simplicity and effectiveness of the GRU architecture make it a popular choice in deep learning
    applications.
  </p>
</div>